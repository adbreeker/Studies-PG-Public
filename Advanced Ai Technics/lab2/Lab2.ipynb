{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1eb5064d-2e7e-49a5-9f2f-6b0dbb65b42c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`low_cpu_mem_usage` was None, now default to True since model is quantized.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b736046a28154689a92c4a5b4e8ab3e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from peft import PeftModel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"mistralai/Mistral-7B-v0.1\",\n",
    "    token='')\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"mistralai/Mistral-7B-v0.1\",\n",
    "    quantization_config=BitsAndBytesConfig(load_in_4bit=True),\n",
    "    token='')\n",
    "\n",
    "#memory used 4544Mib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0365a632-8e76-4dae-84d4-2ee20ece6255",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs id:\n",
      "tensor([[    1,  1824,  3181,   349, 11495, 10109, 28804]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/student/miniconda3/envs/s207250/lib/python3.12/site-packages/bitsandbytes/nn/modules.py:451: UserWarning: Input type into Linear4bit is torch.float16, but bnb_4bit_compute_dtype=torch.float32 (default). This will lead to slow inference or training speed.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "output:\n",
      "<s> What color is classic grass?\n",
      "\n",
      "Green.\n",
      "\n",
      "What color is the grass in the field?\n",
      "\n",
      "Green.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#task2\n",
    "\n",
    "encoded = tokenizer.encode(\"What color is classic grass?\", return_tensors=\"pt\")\n",
    "print(\"inputs id:\")\n",
    "print(encoded)\n",
    "\n",
    "outputs = model.generate(\n",
    "    encoded.to(\"cuda\"),\n",
    "    #max_length = 100,\n",
    "    return_dict_in_generate=True,\n",
    "    output_scores=True,\n",
    ")\n",
    "\n",
    "print()\n",
    "print(\"output:\")\n",
    "for sentence in outputs[0]:\n",
    "    print(tokenizer.decode(sentence))\n",
    "\n",
    "#odp 1 - The tokenized input IDs are the unique identifiers of the input data. They are used to identify the input data in the system and to track its progress through the system.\n",
    "#odp 2 - I’m trying to understand the model.generate() output, and I’m not sure what the keys are, and what they contain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7ecaf7-b378-4a18-904b-8150c71c3282",
   "metadata": {},
   "outputs": [],
   "source": [
    "#task3\n",
    "\n",
    "peftModel = PeftModel.from_pretrained(\n",
    "    model,\n",
    "    \"alignment-handbook/zephyr-7b-sft-qlora\", \n",
    "    quantization_config=BitsAndBytesConfig(load_in_4bit=True),\n",
    "    token='' #add token\n",
    ")\n",
    "\n",
    "peftTokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"alignment-handbook/zephyr-7b-sft-qlora\", \n",
    "    token='' #add token\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0fdc1b7-2b67-495b-b780-e753ef17f006",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[523,\n",
       " 28766,\n",
       " 6574,\n",
       " 28766,\n",
       " 28767,\n",
       " 13,\n",
       " 7020,\n",
       " 460,\n",
       " 4314,\n",
       " 1742,\n",
       " 297,\n",
       " 1342,\n",
       " 3098,\n",
       " 2939,\n",
       " 2,\n",
       " 28705,\n",
       " 13,\n",
       " 28789,\n",
       " 28766,\n",
       " 1838,\n",
       " 28766,\n",
       " 28767,\n",
       " 13,\n",
       " 6802,\n",
       " 349,\n",
       " 574,\n",
       " 6656,\n",
       " 11314,\n",
       " 2,\n",
       " 28705,\n",
       " 13,\n",
       " 28789,\n",
       " 28766,\n",
       " 489,\n",
       " 11143,\n",
       " 28766,\n",
       " 28767,\n",
       " 13,\n",
       " 1916,\n",
       " 6656,\n",
       " 11314,\n",
       " 349,\n",
       " 2513,\n",
       " 1827,\n",
       " 2,\n",
       " 28705,\n",
       " 13]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#task 4\n",
    "\n",
    "chatTemplateDict1 = [\n",
    "    {\"role\": \"system\", \"content\": \"you are villager in medival country\"},\n",
    "    {\"role\": \"user\", \"content\": \"what is your favorite meal\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"my favorite meal is potato\"}\n",
    "]\n",
    "\n",
    "peftTokenizer.apply_chat_template(chatTemplateDict1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c5185ce-847f-4dc6-9484-855c418670ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{% for message in messages %}\\n{% if message['role'] == 'user' %}\\n{{ '<|user|>\\n' + message['content'] + eos_token }}\\n{% elif message['role'] == 'system' %}\\n{{ '<|system|>\\n' + message['content'] + eos_token }}\\n{% elif message['role'] == 'assistant' %}\\n{{ '<|assistant|>\\n'  + message['content'] + eos_token }}\\n{% endif %}\\n{% if loop.last and add_generation_prompt %}\\n{{ '<|assistant|>' }}\\n{% endif %}\\n{% endfor %}\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peftTokenizer.chat_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70b28b5e-2a0e-4fff-a32a-8225205b2535",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|system|>\\nyou are villager in medival country</s>\\n<|user|>\\nwhat is your favorite meal</s>\\n<|assistant|>\\nmy favorite meal is potato</s>\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peftTokenizer.apply_chat_template(chatTemplateDict1, tokenize = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a86522e-b4f8-4863-a190-e54813830065",
   "metadata": {},
   "outputs": [],
   "source": [
    "chatTemplateDict2 = [\n",
    "    {\"role\": \"system\", \"content\": \"you are villager in medival country\"},\n",
    "    {\"role\": \"system\", \"content\": \"your favorite meal is potato\"},\n",
    "    {\"role\": \"system\", \"content\": \"you spend most of the days on your farmlands\"},\n",
    "    {\"role\": \"system\", \"content\": \"you had 10 children but now you only have 3\"}\n",
    "]\n",
    "\n",
    "peftTokenizer.apply_chat_template(chatTemplateDict2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
