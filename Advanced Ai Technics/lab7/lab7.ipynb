{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67c89ee2-6e0b-468a-a047-d3a8e85d336b",
   "metadata": {},
   "source": [
    "# I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad9c5156-c0bb-452b-8b4a-467181eff261",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/student/miniconda3/envs/s207250/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "#1.1\n",
    "dataset = load_dataset(\"tcltcl/small-simple-wikipedia\")\n",
    "texts = dataset['train']['text']\n",
    "\n",
    "#1.2\n",
    "chunk_size = 200\n",
    "overlap = 50\n",
    "\n",
    "#1.3\n",
    "chunks = []\n",
    "for text in texts:\n",
    "    words = text.split()\n",
    "    for i in range(0, len(words), chunk_size - overlap):\n",
    "        chunk = ' '.join(words[i:i + chunk_size])\n",
    "        if chunk.strip():\n",
    "            chunks.append(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "887ffb9e-7107-49f9-acea-a7fdb0872a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.1 \n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "#2.2 \n",
    "retriever_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "#2.3\n",
    "embeddings = retriever_model.encode(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "670916e0-ee29-4d06-8263-7c48b40a92ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.1 \n",
    "def retriever(question):\n",
    "    #3.2\n",
    "    question_embedding = retriever_model.encode([question])\n",
    "    \n",
    "    #3.3 \n",
    "    similarities = retriever_model.similarity(question_embedding, embeddings)\n",
    "    \n",
    "    #3.4 \n",
    "    best_chunk_idx = np.argmax(similarities)\n",
    "    return chunks[best_chunk_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47356eb1-ab37-4614-b030-09e2c057087b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:01<00:00,  4.47it/s]\n",
      "Some parameters are on the meta device because they were offloaded to the cpu.\n"
     ]
    }
   ],
   "source": [
    "#4.1\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"HuggingFaceH4/zephyr-7b-beta\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"HuggingFaceH4/zephyr-7b-beta\",\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "#4.2\n",
    "def create_prompt(question, retrieved_context):\n",
    "    return f\"<|user|>\\nUse the following context to answer the question.\\n\\nContext: {retrieved_context}\\n\\nQuestion: {question}\\n<|assistant|>\"\n",
    "\n",
    "def rag_answer(question):\n",
    "    retrieved_context = retriever(question)\n",
    "    \n",
    "    prompt = create_prompt(question, retrieved_context)\n",
    "    \n",
    "    #4.3\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    \n",
    "    #4.4\n",
    "    output = model.generate(**inputs)\n",
    "    \n",
    "    #4.5\n",
    "    answer = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    \n",
    "    #4.6\n",
    "    #answer = answer.split(\"<|assistant|>\")[-1].strip()\n",
    "    \n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cefb52a5-3b8a-46db-a38f-a291de099e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is AI?\n",
      "Answer: <|user|>\n",
      "Use the following context to answer the question.\n",
      "\n",
      "Context: control large and small machines which in the past were controlled by humans. Most people have used a personal computer in their home or at work. They are used for things such as calculation, listening to music, reading an article, writing, playing games etc Hardware Modern computers are electronic computer hardware. They do mathematical arithmetic very quickly but computers do not really \"think\". They only follow the instructions in their software programs. The software uses the hardware when the user gives it instructions, and gives useful outputs. Controls Computers are controlled with user interfaces. Input devices which include keyboards, computer mice, buttons, and touch screens, etc. Programs Computer programs are designed or written by computer programmers. A few programmers write programs in the computer's own language called machine code. Most programs are written using a programming language like C, C++, Java. These programming languages are more like the language with which one talks and writes every day. The compiler converts the user's instructions into binary code (machine code) that the computer will understand and do what is needed. History of computers Automation Most people have a problem with math. To show this, try doing 584 x 3,220 in your mind.\n",
      "\n",
      "Question: What is AI?\n",
      "<|assistant|>\n",
      "AI, or artificial intelligence, is not the same as computers. While computers can perform calculations and\n"
     ]
    }
   ],
   "source": [
    "question = \"What is compil?\"\n",
    "answer = rag_answer(question)\n",
    "print(f\"Question: {question}\")\n",
    "print(f\"Answer: {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c609d9-2d5b-4de7-9433-2172ed37eea7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
