{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "690a0001-0595-4ed4-bdeb-cdbf7c152f09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 1280)\n",
       "    (wpe): Embedding(1024, 1280)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-35): 36 x GPT2Block(\n",
       "        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D(nf=3840, nx=1280)\n",
       "          (c_proj): Conv1D(nf=1280, nx=1280)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D(nf=5120, nx=1280)\n",
       "          (c_proj): Conv1D(nf=1280, nx=5120)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1280, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"openai-community/gpt2-large\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"openai-community/gpt2-large\")\n",
    "device = torch.device(\"cuda\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b205e5ff-bdf9-41f9-85ff-7b63624995af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, set_seed\n",
    "generator = pipeline('text-generation', model='gpt2-large')\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3461b9f8-20f2-4144-8618-d8528e0c10c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': '2+2=7'},\n",
       " {'generated_text': '2+2=4'},\n",
       " {'generated_text': '2+2=3'},\n",
       " {'generated_text': '2+2=7'},\n",
       " {'generated_text': '2+2=7'}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator(\"2+2=\", max_length=5, num_return_sequences=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45744efd-d1bd-445f-a169-36b288b13366",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'if 2+1=3 and 2+3=5 and 1+1=2 then 2+2=3*2=3*5 and 1+3=1=2 and so on.\\n\\nWhat if all 3 of the'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator(\"if 2+1=3 and 2+3=5 and 1+1=2 then 2+2=\", truncation=True, num_return_sequences=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90e89d54-c85b-41ea-93f6-34f2d3d4a9ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"Ala's mom calls her Ala, Tomek's mom calls him Tomek, Adam's mom calls him Adam, and finally in the end they have one mother and one son.\\n\\nThe two have come to terms with the same reality:\"}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator(\"Ala's mom calls her Ala, Tomek's mom calls him Tomek, Adam's mom calls him\", truncation=True, num_return_sequences=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8a3b8f5-69ed-47e4-ab95-95c403ca9535",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'alphabet is abcdefghijkl, a is first letter in alphabet, b is second letter in alphabet, d is forth letter in albhabet, is e fith letter? yes. Is c the third letter? yes.'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator(\"alphabet is abcdefghijkl, a is first letter in alphabet, b is second letter in alphabet, d is forth letter in albhabet, is e fith letter? yes. Is c the third letter?\", truncation=True, num_return_sequences=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
